{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987ca52c",
   "metadata": {},
   "source": [
    "# Avocado Prices Data Analysis\n",
    "\n",
    "This notebook explores historical avocado price data across multiple U.S. regions and avocado types.  \n",
    "The goal of this analysis is to identify trends, seasonal patterns, and differences between organic and conventional avocados using structured datasets provided in multiple formats (CSV, JSON, Excel, SQLite).\n",
    "\n",
    "This project follows the data science lifecycle, including:\n",
    "\n",
    "- Data loading and inspection\n",
    "- Data cleaning and preparation\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Visualization and interpretation\n",
    "- Cross-format data integration\n",
    "- Validation using SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfc3ec9",
   "metadata": {},
   "source": [
    "## Setup and Library Imports\n",
    "\n",
    "The analysis begins by importing the required Python libraries. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff671af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f30ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f33f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8bcae6",
   "metadata": {},
   "source": [
    "## Loading the Primary Dataset (CSV)\n",
    "\n",
    "The primary avocado dataset is loaded from a CSV file obtained from Kaggle.  \n",
    "This dataset contains historical price and sales volume information across multiple regions and avocado types.\n",
    "\n",
    "Initial inspection steps are performed to understand the dataset structure, including:\n",
    "\n",
    "- Viewing sample rows\n",
    "- Checking dataset dimensions\n",
    "- Examining data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701e3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"avocado.csv\")\n",
    "df.head()\n",
    "df.shape\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cca59a",
   "metadata": {},
   "source": [
    "## Initial Exploratory Data Analysis (EDA)\n",
    "\n",
    "Before cleaning the data, exploratory analysis is performed to understand the dataset’s characteristics.\n",
    "\n",
    "Key checks include:\n",
    "\n",
    "- Summary statistics\n",
    "- Missing values\n",
    "- Unique categories (type and region)\n",
    "\n",
    "This step helps identify necessary cleaning operations and guides later analysis decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "df.isna().sum()\n",
    "df['type'].unique()\n",
    "df['region'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4def429",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation\n",
    "\n",
    "Several preprocessing steps are required to ensure the dataset is suitable for analysis:\n",
    "\n",
    "- The `Date` column is converted to a datetime format for time-based analysis.\n",
    "- Numeric fields such as `AveragePrice` and `Total Volume` are validated.\n",
    "- Missing or inconsistent values are handled.\n",
    "- New features (Year and Month) are created to enable seasonal analysis.\n",
    "\n",
    "These transformations improve data quality and analytical flexibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AveragePrice'] = pd.to_numeric(df['AveragePrice'], errors='coerce')\n",
    "df['Total Volume'] = pd.to_numeric(df['Total Volume'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb1d662",
   "metadata": {},
   "source": [
    "## Data Visualization and Trend Analysis\n",
    "\n",
    "Visualizations are used to reveal patterns that are difficult to detect from raw tables alone.\n",
    "\n",
    "The following aspects are explored:\n",
    "\n",
    "- Price trends over time\n",
    "- Organic vs. conventional comparisons\n",
    "- Regional price differences\n",
    "- Seasonal price behavior\n",
    "\n",
    "Each visualization is followed by interpretation to connect graphical patterns with meaningful insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a98db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.groupby('Date')['AveragePrice'].mean().plot()\n",
    "plt.title(\"Average Avocado Price Over Time\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99bf5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.boxplot(data=df, x='type', y='AveragePrice')\n",
    "plt.title(\"Price Distribution by Avocado Type\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cb005",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot(data=df, x='region', y='AveragePrice')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Average Price by Region\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(data=df, x='Month', y='AveragePrice')\n",
    "plt.title(\"Seasonal Price Trends\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2fc8e2",
   "metadata": {},
   "source": [
    "## Loading Secondary Dataset (JSON – New York)\n",
    "\n",
    "A secondary dataset containing New York observations is loaded from a JSON file.\n",
    "\n",
    "This file uses JSON Lines format and stores dates as Unix timestamps in milliseconds.  \n",
    "To correctly interpret the data:\n",
    "\n",
    "- JSON Lines parsing is enabled\n",
    "- Automatic date conversion is disabled\n",
    "- Dates are manually converted using Pandas\n",
    "\n",
    "This step highlights real-world challenges associated with this data format. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"avocado_secondary_NY.json\", \"r\") as f:\n",
    "    print(f.read()[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b213790",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_df = pd.read_json(\n",
    "    \"avocado_secondary_NY.json\",\n",
    "    lines=True,\n",
    "    convert_dates=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c628cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_df['Date'] = pd.to_datetime(ny_df['Date'], unit='ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_df = pd.read_json(\"avocado_secondary_NY.json\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587dd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_df = pd.read_json(\n",
    "    \"avocado_secondary_NY.json\",\n",
    "    lines=True,\n",
    "    convert_dates=False\n",
    ")\n",
    "\n",
    "ny_df['Date'] = pd.to_datetime(ny_df['Date'], unit='ms')\n",
    "\n",
    "ny_df.head()\n",
    "ny_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d34a0c",
   "metadata": {},
   "source": [
    "## Loading Secondary Dataset (Excel – San Francisco)\n",
    "\n",
    "San Francisco data is provided in Excel format.  \n",
    "Reading Excel files in Pandas requires the optional dependency `openpyxl`, which serves as the engine for `.xlsx` files.\n",
    "\n",
    "After loading, the dataset is inspected to verify:\n",
    "\n",
    "- Column structure\n",
    "- Data types\n",
    "- Compatibility with other datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38085ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = pd.read_excel(\"avocado_secondary_SF.xlsx\")\n",
    "sf_df.head()\n",
    "sf_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cad2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_df['Date'] = pd.to_datetime(ny_df['Date'])\n",
    "sf_df['Date'] = pd.to_datetime(sf_df['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_df.columns\n",
    "sf_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c71d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df.rename(columns={'Average Price': 'AveragePrice'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0648bed",
   "metadata": {},
   "source": [
    "## Merging JSON and Excel Datasets\n",
    "\n",
    "The New York and San Francisco datasets are combined to reconstruct a multi-region dataset.\n",
    "\n",
    "Before merging:\n",
    "\n",
    "- Column names are aligned\n",
    "- Data types are standardized\n",
    "- Date formats are verified\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebde17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_secondary = pd.concat([ny_df, sf_df], ignore_index=True)\n",
    "merged_secondary.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f41d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_secondary.describe()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cae0f0",
   "metadata": {},
   "source": [
    "## Validation Using SQLite Database\n",
    "\n",
    "To verify dataset consistency, the merged dataset is compared against the SQLite database version.\n",
    "\n",
    "Validation checks include:\n",
    "\n",
    "- Column alignment\n",
    "- Data type comparisons\n",
    "- Row counts\n",
    "- Summary statistics\n",
    "\n",
    "This process ensures that transformations and merges preserved data integrity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"avocado_secondary_ALL.db\")\n",
    "\n",
    "sql_df = pd.read_sql_query(\"SELECT * FROM avocado_all\", conn)\n",
    "sql_df.info()\n",
    "sql_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fff7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(sql_df.columns) - set(merged_secondary.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b74509d",
   "metadata": {},
   "source": [
    "## Exporting Processed Data\n",
    "\n",
    "A filtered subset of the cleaned dataset is exported to a new structured format.\n",
    "\n",
    "Exporting data is a common step in real-world workflows, enabling:\n",
    "\n",
    "- Data sharing\n",
    "- Reproducibility\n",
    "- Downstream analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e81b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "organic_df = df[df['type'] == 'organic']\n",
    "organic_df.to_csv(\"organic_avocados.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210049ef",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This analysis demonstrated the full data science workflow, including data cleaning, visualization, cross-format integration, and validation.\n",
    "\n",
    "Key insights include:\n",
    "\n",
    "- Observable price fluctuations over time\n",
    "- Differences between avocado types\n",
    "- Regional variation\n",
    "- Seasonal effects\n",
    "\n",
    "The project also reinforced the importance of handling file formats, data types, and reproducible workflows.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
